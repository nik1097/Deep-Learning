{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_batch_size, test_batch_size):\n",
    "    # Fetch training data: total 60000 samples\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train = True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.Resize((32, 32)),\n",
    "                           transforms.ToTensor()\n",
    "                       ])),\n",
    "        batch_size = train_batch_size, shuffle=True)\n",
    "\n",
    "    # Fetch test data: total 10000 samples\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('data', train = False, transform=transforms.Compose([\n",
    "            transforms.Resize((32, 32)),\n",
    "            transforms.ToTensor()\n",
    "        ])),\n",
    "        batch_size = test_batch_size, shuffle=True)\n",
    "\n",
    "    return (train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        # flatten as one dimension\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sensitivity(model):\n",
    "    fNormAll = 0\n",
    "    counter = 0\n",
    "    for p in model.parameters():\n",
    "        grad = 0.0\n",
    "        if p.grad is not None:\n",
    "            grad = p.grad\n",
    "            fNorm = torch.linalg.norm(grad).numpy()\n",
    "            fNormAll += fNorm\n",
    "            counter += 1\n",
    "    return fNormAll / counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_optimizer(model):\n",
    "    return optim.Adam(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, optimizer, train_loader):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    counter = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        counter += 1\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward propagation\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data\n",
    "        \n",
    "        pred = np.argmax(output.data, axis=1)\n",
    "        correct += np.equal(pred, target.data).sum()\n",
    "\n",
    "    train_loss = (train_loss * batch) / len(train_loader.dataset)\n",
    "    acc = 100.0 * correct / len(train_loader.dataset)\n",
    "    return train_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        \n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        test_loss += loss.data\n",
    "        pred = np.argmax(output.data, axis=1)\n",
    "        correct += np.equal(pred, target.data).sum()\n",
    "        \n",
    "    test_loss = (test_loss * batch) / len(test_loader.dataset)\n",
    "    acc = 100.0 * correct / len(test_loader.dataset)\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute(model, optimizer):\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        tr_loss, train_acc = train(model, optimizer, train_loader)\n",
    "        t_loss, test_acc = test(model, test_loader)\n",
    "        loss_train_arr.append(tr_loss)\n",
    "        loss_test_arr.append(t_loss)\n",
    "        print(\"Model Train loss: \", tr_loss)\n",
    "        print(\"Model Test loss: \", t_loss)\n",
    "        train_acc_arr.append(train_acc)\n",
    "        test_acc_arr.append(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_train_arr = []\n",
    "loss_test_arr = []\n",
    "test_acc_arr = []\n",
    "train_acc_arr = []\n",
    "sensList= []\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Train loss:  tensor(0.7664)\n",
      "Model Test loss:  tensor(0.2415)\n",
      "Model Train loss:  tensor(0.1978)\n",
      "Model Test loss:  tensor(0.1401)\n",
      "Model Train loss:  tensor(0.1245)\n",
      "Model Test loss:  tensor(0.0888)\n",
      "Model Train loss:  tensor(0.0950)\n",
      "Model Test loss:  tensor(0.0708)\n",
      "Model Train loss:  tensor(0.0775)\n",
      "Model Test loss:  tensor(0.0636)\n",
      "Model Train loss:  tensor(0.0671)\n",
      "Model Test loss:  tensor(0.0515)\n",
      "Model Train loss:  tensor(0.0589)\n",
      "Model Test loss:  tensor(0.0501)\n",
      "Model Train loss:  tensor(0.0525)\n",
      "Model Test loss:  tensor(0.0426)\n",
      "Model Train loss:  tensor(0.0459)\n",
      "Model Test loss:  tensor(0.0425)\n",
      "Model Train loss:  tensor(0.0415)\n",
      "Model Test loss:  tensor(0.0385)\n",
      "0.07655004835687577\n"
     ]
    }
   ],
   "source": [
    "batch_size = [500]\n",
    "for batch in batch_size:\n",
    "    torch.manual_seed(1)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    train_loader, test_loader = load_data(batch, batch)\n",
    "    model1 = CNN()\n",
    "    optimizer = define_optimizer(model1)\n",
    "    compute(model1, optimizer)\n",
    "    print(sensitivity(model1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5a03e6978a913b76a01264f69485476c06bb2afb04825931e6a903524ca57e27"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
