{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dad6bb00-bfe1-42eb-a4e9-5e27772d084c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac56942a-48d5-4901-8577-2b1f383a5916",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/scratch1/nsuresh/DL/'\n",
    "with open(filepath + 'training_label.json', 'r') as f:\n",
    "    file = json.load(f)\n",
    "\n",
    "word_count = {}\n",
    "for d in file:\n",
    "    for s in d['caption']:\n",
    "        word_sentence = re.sub('[.!,;?]]', ' ', s).split()\n",
    "        for word in word_sentence:\n",
    "            word = word.replace('.', '') if '.' in word else word\n",
    "            if word in word_count:\n",
    "                word_count[word] += 1\n",
    "            else:\n",
    "                word_count[word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6e78e24-c338-408d-b4b7-611c886fe653",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = {}\n",
    "for word in word_count:\n",
    "    if word_count[word] > 10:\n",
    "        word_dict[word] = word_count[word]\n",
    "useful_tokens = [('<PAD>', 0), ('<SOS>', 1), ('<EOS>', 2), ('<UNK>', 3)]\n",
    "i2w = {i + len(useful_tokens): w for i, w in enumerate(word_dict)}\n",
    "w2i = {w: i + len(useful_tokens) for i, w in enumerate(word_dict)}\n",
    "for token, index in useful_tokens:\n",
    "    i2w[index] = token\n",
    "    w2i[token] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb570c2a-63e2-41eb-a517-704302378d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def s_split(sentence):\n",
    "    sentence = re.sub(r'[.!,;?]', ' ', sentence).split()\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i] not in word_dict:\n",
    "            sentence[i] = 3\n",
    "        else:\n",
    "            sentence[i] = w2i[sentence[i]]\n",
    "    sentence.insert(0, 1)\n",
    "    sentence.append(2)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab300cb0-fa30-4594-a95f-15f772a40543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate(label_file):\n",
    "    #label_json = filepath + 'training_label.json'\n",
    "    label_json = filepath + label_file\n",
    "    annotated_caption = []\n",
    "    with open(label_json, 'r') as f:\n",
    "        label = json.load(f)\n",
    "    for d in label:\n",
    "        for s in d['caption']:\n",
    "            s = s_split(s)\n",
    "            annotated_caption.append((d['id'], s))\n",
    "    return annotated_caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804540ea-bf55-4cf5-9468-2577cc6c543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avi(files_dir):\n",
    "    avi_data = {}\n",
    "    #training_feats = filepath + '/training_data/feat'\n",
    "    training_feats = filepath + files_dir\n",
    "    files = os.listdir(training_feats)\n",
    "    for file in files:\n",
    "        value = np.load(os.path.join(training_feats, file))\n",
    "        avi_data[file.split('.npy')[0]] = value\n",
    "    return avi_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "341949e4-ed2d-4e32-9a5b-894f4617249f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minibatch(data):\n",
    "    data.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "    avi_data, captions = zip(*data) \n",
    "    avi_data = torch.stack(avi_data, 0)\n",
    "\n",
    "    # Merge captions (from tuple of 1D tensor to 2D tensor).\n",
    "    lengths = [len(cap) for cap in captions]\n",
    "    targets = torch.zeros(len(captions), max(lengths)).long()\n",
    "    for i, cap in enumerate(captions):\n",
    "        end = lengths[i]\n",
    "        targets[i, :end] = cap[:end]\n",
    "    return avi_data, targets, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b703c0-f26d-4819-8bd1-f643706059e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class training_data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.label_file = label_file\n",
    "        self.files_dir = files_dir\n",
    "        self.avi = avi(label_file)\n",
    "        self.data_pair = annotate(files_dir)\n",
    "    def __len__(self):\n",
    "        return len(self.data_pair)\n",
    "    def __getitem__(self, idx):\n",
    "        assert (idx < self.__len__())\n",
    "        avi_file_name, sentence = self.data_pair[idx]\n",
    "        data = torch.Tensor(self.avi[avi_file_name])\n",
    "        data += torch.Tensor(data.size()).random_(0, 2000)/10000.\n",
    "        return torch.Tensor(data), torch.Tensor(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faefa1ff-0336-4b9d-869c-601665f893b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = '/training_data/feat'\n",
    "files_dir = 'training_label.json'\n",
    "train_dataset = training_data()\n",
    "train_dataloader = DataLoader(dataset = train_dataset, batch_size=128, shuffle=True, num_workers=8, collate_fn=minibatch)\n",
    "\n",
    "label_file = '/testing_data/feat'\n",
    "files_dir = 'testing_label.json'\n",
    "test_dataset = training_data()\n",
    "test_dataloader = DataLoader(dataset = test_dataset, batch_size=128, shuffle=True, num_workers=8, collate_fn=minibatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f8946d-a0c2-4a43-b979-a4c0e2c84642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
